train:
  trainer: 'HardestContrastiveLossTrainer'
  save_freq_epoch: 3
  val_batch_size: 1
  out_dir: '20230821-ExpLR-train-resume-debug'

  # Hard negative mining
  use_hard_negative: True
  hard_negative_sample_ratio: 0.05
  hard_negative_max_num: 3000
  num_pos_per_batch: 1024
  num_hn_samples_per_batch: 256

  # Metric learning loss
  neg_thresh: 3.0
  pos_thresh: 0.4
  neg_weight: 1
  
  # Data loader configs
  train_phase: 'train'
  val_phase: 'val'
  test_phase: 'test'

  stat_freq: 20
  test_valid: True
  val_max_iter: 3000
  val_epoch_freq: 1
  positive_pair_search_voxel_size_multiplier: 1.5
  hit_ratio_thresh: 2.

  # dNetwork specific configurations
  model: 'ResUNetBN2C'
  in_channels: 1
  model_n_out: 32
  conv1_kernel_size: 5
  normalize_feature: True
  dist_type: 'L2'
  best_val_metric: 'feat_match_ratio'

  # Optimizer arguments
  optimizer: 'Adam'
  # For SGD
  momentum: 0.9
  # For Adam
  adam_beta1: 0.9
  adam_beta2: 0.999
  # For both SGD and Adam
  weight_decay: 0.0001
  iter_size: 1 # accumulate gradient
  bn_momentum: 0.05

  max_epoch: 100
  lr: 0.003
  scheduler: 'ExpLR'
  # For ExpLR
  exp_gamma: 0.99
  # For OneCycleLR
  max_lr: .01

  # Misc
  use_gpu: True
  weights: #'KITTI-v0.3-ResUNetBN2C-conv1-5-nout32.pth'
  weights_dir: 
  resume: 
  resume_dir: '20230818-ExpLR-train/20230818-15-49-41' #'20230811-tmp69-70-clean-.6overlap-train-output'
  train_num_thread: 1
  val_num_thread: 1
  test_num_thread: 1
  fast_validation: False
  nn_max_n: 500 # The maximum number of features to find nearest neighbors in batch
